{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOigyzLc4CiRqzFarGLVZ6S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/divya-r-kamat/kn-bpe-tokenizer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfxspP1admiJ",
        "outputId": "f71fc5f2-16f3-4dd3-d109-cbafbc433fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kn-bpe-tokenizer'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (18/18), 10.79 KiB | 10.79 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk6-t2h9rmXx"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# This has translations including literary content\n",
        "dataset = load_dataset(\"ai4bharat/samanantar\", \"kn\", split=\"train\", streaming=True)\n",
        "\n",
        "texts = []\n",
        "for i, example in enumerate(dataset):\n",
        "    if i >= 10000:\n",
        "        break\n",
        "    texts.append(example['tgt'])  # Kannada side\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"Loaded {i + 1} texts...\")\n",
        "\n",
        "full_text = '\\n\\n'.join(texts)\n",
        "with open('kannada_samanantar.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(full_text)\n",
        "\n",
        "print(f\"Saved to kannada_samanantar.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer Training"
      ],
      "metadata": {
        "id": "ISON7TNdW1m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/kn-bpe-tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt9-CiLhZ1gJ",
        "outputId": "65c977b2-c0e7-4f01-9876-de4464fc0927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kn-bpe-tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRTZ1hEGZ4ky",
        "outputId": "1365cd2d-8cd9-4eb1-92bc-7e4e0a5595b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rREADME.md: 0.00B [00:00, ?B/s]\rREADME.md: 11.4kB [00:00, 23.9MB/s]\n",
            "Loaded 1000 texts...\n",
            "Loaded 2000 texts...\n",
            "Loaded 3000 texts...\n",
            "Loaded 4000 texts...\n",
            "Loaded 5000 texts...\n",
            "Loaded 6000 texts...\n",
            "Loaded 7000 texts...\n",
            "Loaded 8000 texts...\n",
            "Loaded 9000 texts...\n",
            "Loaded 10000 texts...\n",
            "Saved to data/kannada_samanantar.txt\n",
            "Training tokenizer with vocab size: 5000\n",
            "Initial vocab size (unique characters): 195\n",
            "Training on 576848 characters\n",
            "Merged 1000/4805 pairs, vocab size: 1195\n",
            "Merged 2000/4805 pairs, vocab size: 2195\n",
            "Merged 3000/4805 pairs, vocab size: 3195\n",
            "Merged 4000/4805 pairs, vocab size: 4195\n",
            "\n",
            "============================================================\n",
            "Training Complete!\n",
            "============================================================\n",
            "Final vocab size: 5000\n",
            "Original characters: 576848\n",
            "Final BPE tokens: 153632\n",
            "Compression ratio: 3.75x\n",
            "============================================================\n",
            "\n",
            "Saved vocabulary to model/vocab.json\n"
          ]
        }
      ]
    }
  ]
}